loading data...applying decomposition
done.
training model 0
bag 1 of 50
bag 0 of 50
bag 3 of 50
bag 2 of 50
bag 5 of 50
bag 4 of 50
bag 6 of 50
bag 7 of 50
bag 8 of 50
bag 9 of 50
bag 10 of 50
bag 11 of 50
bag 12 of 50
bag 13 of 50
bag 14 of 50
bag 15 of 50
bag 16 of 50
bag 17 of 50
bag 18 of 50
bag 19 of 50
bag 20 of 50
bag 21 of 50
bag 22 of 50
bag 23 of 50
bag 24 of 50
bag 25 of 50
bag 26 of 50
bag 27 of 50
bag 28 of 50
bag 29 of 50
bag 30 of 50
bag 31 of 50
bag 32 of 50
bag 33 of 50
bag 34 of 50
bag 35 of 50
bag 36 of 50
bag 37 of 50
bag 38 of 50
bag 39 of 50
bag 40 of 50
bag 41 of 50
bag 42 of 50
bag 43 of 50
bag 44 of 50
bag 45 of 50
bag 46 of 50
bag 47 of 50
bag 48 of 50
bag 49 of 50
training model 1
bag 5 of 50
bag 1 of 50bag 4bag 2 of 50

bag 3 of 50
 of 50
bag 6 of 50
bag 7 of 50
bag 0 of 50
bag 8 of 50
bag 9 of 50
bag 10 of 50
bag 11 of 50
bag 12 of 50
bag 13 of 50
bag 14 of 50
bag 15 of 50
bag 16 of 50
bag 17 of 50
bag 18 of 50
bag 19 of 50
bag 20 of 50
bag 21 of 50
bag 22 of 50
bag 23 of 50
bag 24 of 50
bag 25 of 50
bag 26 of 50
bag 27 of 50
bag 28 of 50
bag 29 of 50
bag 30 of 50
bag 31 of 50
bag 32 of 50
bag 33 of 50
bag 34 of 50
bag 35 of 50
bag 36 of 50
bag 37 of 50
bag 38 of 50
bag 39 of 50
bag 40 of 50
bag 41 of 50
bag 42 of 50
bag 43 of 50
bag 44 of 50
bag 45 of 50
bag 46 of 50
bag 47 of 50
bag 48 of 50
bag 49 of 50
training model 2
bag 3 of 50
bag 0 of 50
bag 4 of 50
bag 1 of 50
bag 5 of 50
bag 2 of 50
bag 7 of 50
bag 6 of 50
bag 8 of 50
bag 9 of 50
bag 10 of 50
bag 11 of 50
bag 12 of 50
bag 13 of 50
bag 14 of bag 50
15 of 50
bag 16 of 50
bag 17 of 50
bag 18 of 50
bag 19 of 50
bag 20 of 50
bag 21 of 50
bag 22 of 50
bag 23 of 50
bag 24 of 50
bag 25 of 50
bag 26 of 50
bag 27 of 50
bag 28 of 50
bag 29 of 50
bag 30 of 50
bag 31 of 50
bag 32 of 50
bag 33 of 50
bag 34 of 50
bag 35 of 50
bag 36 of 50
bag 37 of 50
bag 38 of 50
bag 39 of 50
bag 40 of 50
bag 41 of 50
bag 42 of 50
bag 43 of 50
bag 44 of 50
bag 45 of 50
bag 46 of 50
bag 47 of 50
bag 48 of 50
bag 49 of 50
training model 3
bag 1 of 50
bag 4 of 50
bag 5 of 50
bag 0 of 50
bag 3 of 50
bag 6 of 50
bag 7 of 50
bag 2 of 50
bag 8 of 50bag 
9 of 50
bag 10 of 50
bag 11 of 50
bag 12 of 50
bag 13 of 50
bag 14 of 50
bag 15 of 50
bag 16 of 50
bag 17 of 50
bag 18 of 50
bag 19 of 50
bag 20 of 50
bag 21 of 50
bag 22 of 50
bag 23 of 50
bag 24 of 50
bag 25 of 50
bag 26 of 50
bag 27 of 50
bag 28 of 50
bag 29 of 50
bag 30 of 50
bag 31 of 50
bag 32 of 50
bag 33 of 50
bag 34 of 50
bag 35 of 50
bag 36 of 50
bag 37 of 50
bag 38 of 50
bag 39 of 50
bag 40 of 50
bag 41 of 50
bag 42 of 50
bag 43 of 50
bag 44 of 50
bag 45 of 50
bag 46 of 50
bag 47 of 50
bag 48 of 50
bag 49 of 50
training model 4
bag 0 of 50
bag 1 of 50
bag 2 of bag 3 of 50
50
bag 4 of 50
bag 5 of 50
bag 6 of 50
bag 7 of 50
bag 8 of 50
bag 9 of 50
bag 10 of 50
bag 11 of 50
bag 12 of 50
bag 13 of 50
bag 14 of 50
bag 15 of 50
bag 16 of 50
bag 17 of 50
bag 18 of 50
bag 19 of 50
bag 20 of 50
bag 21 of 50
bag 22 of 50
bag 23 of 50
bag 24 of 50
bag 25 of 50
bag 26 of 50
bag 27 of 50
bag 28 of 50
bag 29 of 50
bag 30 of 50
bag 31 of 50
bag 32 of 50
bag 33 of 50
bag 34 of 50
bag 35 of 50
bag 36 of 50
bag 37 of 50
bag 38 of 50
bag 39 of 50
bag 40 of 50
bag 41 of 50
bag 42 of 50
bag 43 of 50
bag 44 of 50
bag 45 of 50
bag 46 of 50
bag 47 of 50
bag 48 of 50
bag 49 of 50
training model 5
bag 4 of 50
bag 2 of 50
bag 1 of 50
bag 0 of 50
bag bag 5 of 50
3 of 50
bag 6 of 50
bag 7 of 50
bag 8 of 50
bag 9 of 50
bag 10 of 50
bag 11 of 50
bag 12 of 50
bag 13 of 50
bag 14 of 50
bag 15 of 50
bag 16 of 50
bag 17 of 50
bag 18 of 50
bag 19 of 50
bag 20 of 50
bag 21 of 50
bag 22 of 50
bag 23 of 50
bag 24 of 50
bag 25 of 50
bag 26 of 50
bag 27 of 50
bag 28 of 50
bag 29 of 50
bag 30 of 50
bag 31 of 50
bag 32 of 50
bag 33 of 50
bag 34 of 50
bag 35 of 50
bag 36 of 50
bag 37 of 50
bag 38 of 50
bag 39 of 50
bag 40 of 50
bag 41 of 50
bag 42 of 50
bag 43 of 50
bag 44 of 50
bag 45 of 50
bag 46 of 50
bag 47 of 50
bag 48 of 50
bag 49 of 50
training model 6
bag 3 of 50
bag bag 1 of 50
bag 4 of 50
bag 5 of 50
bag 2 of 50
bag 6 of 50
0 of 50
bag 7 of 50
bag 8 of 50
bag 9 of 50
bag 10 of 50
bag 11 of 50
bag 12 of 50
bag 13 of 50
bag 14 of 50
bag 15 of 50
bag 16 of 50
bag 17 of 50
bag 18 of 50
bag 19 of 50
bag 20 of 50
bag 21 of 50
bag 22 of 50
bag 23 of 50
bag 24 of 50
bag 25 of 50
bag 26 of 50
bag 27 of 50
bag 28 of 50
bag 29 of 50
bag 30 of 50
bag 31 of 50
bag 32 of 50
bag 33 of 50
bag 34 of 50
bag 35 of 50
bag 36 of 50
bag 37 of 50
bag 38 of 50
bag 39 of 50
bag 40 of 50
bag 41 of 50
bag 42 of 50
bag 43 of 50
bag 44 of 50
bag 45 of 50
bag 46 of 50
bag 47 of 50
bag 48 of 50
bag 49 of 50
training model 7
bag 5 of 50
bag 4 of bag 0 of 50
50
bag 3 of 50
bag bag 2 of 50
6 of 50bag 7 of 50
bag 
1 of 50
bag 8 of 50
bag 9 of 50
bag 10 of 50
bag 11 of 50
bag 12 of 50
bag 13 of 50
bag 14 of 50
bag 15 of 50
bag 16 of 50
bag 17 of 50
bag 18 of 50
bag 19 of 50
bag 20 of 50
bag 21 of 50
bag 22 of 50
bag 23 of 50
bag 24 of 50
bag 25 of 50
bag 27 of 50
bag 26 of 50
bag 28 of 50
bag 29 of 50
bag 30 of 50
bag 31 of 50
bag 32 of 50
bag 33 of 50
bag 34 of 50
bag 35 of 50
bag 36 of 50
bag 37bag  of 50
38 of 50
bag 39 of 50
bag 40 of 50
bag 41 of 50
bag 42 of 50
bag 43 of 50
bag 44 of 50
bag 45 of 50
bag 46 of 50
bag 47 of 50
bag 48 of 50
bag 49 of 50
params = { -0.00316928 0.00368801 0.0553579 0.0246285 0.0353238 0.32549 0.175965 0.0165974 -0.0504221 -0.00685721 -0.05167 0.0307297 0.0246285 0.0599271 -0.112771 0.141618 -0.132154 -0.0102109 -0.0833312 0.051653 0.0383387 -0.00178938 -0.0584625 0.00316928 0.0121195 -0.0065022 0.0450167 0.0246285 0.0447869 -0.0267957 0.0740594 0.0690957 0.0165974 -0.0242711 -0.027814 -0.00497322 -0.00529854 0.00876549 -0.0798297 -0.00185243 0.0442943 -0.0535914 0.101273 -0.0714251 0.182964 -0.0908083 0.0311351 -0.0535914 }
chose model 186 S_rmse_187
chose model 136 S_rmse_137
chose model 193 S_rmse_194
chose model 172 S_rmse_173
chose model 25 S_rmse_26
chose model 20 S_rmse_21
chose model 33 S_rmse_34
chose model 22 S_rmse_23
chose model 179 S_rmse_180
chose model 112 S_rmse_113
processing 3000 predictions...

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
 done.
elapsed: [399.73s cpu, 226401.4105 mticks, 84.71s wall]
score: 0.4398  baseline: 0.4398  diff: 0.00000
category UNKNOWN: count 0 avg error 0 baseline avg error 0 avg improvement 0
category AUTO: count 1249 avg error 0.0269895 baseline avg error 0.0250981 avg improvement -0.0018914
category POSS: count 1531 avg error 0.209267 baseline avg error 0.213126 avg improvement 0.00385906
category IMP: count 220 avg error 1.02813 baseline avg error 1.01199 avg improvement -0.0161384
overall: count 3000 avg error 0.193429 baseline avg error 0.193427 avg improvement -1.53066e-06
worst entries: 
0: 632  label: 1 pred: -0.337489 bl: -0.16695 IMP error_pred: 1.78888 error_bl: 1.36177 improvement: -0.427105
    min: -0.4535  max: 0.416 avg: -0.14468
explanation: 


1: 2793  label: -1 pred: 0.356674 bl: 0.22305 IMP error_pred: 1.84056 error_bl: 1.49585 improvement: -0.344712
    min: -0.0615  max: 0.697 avg: 0.307835
explanation: 


2: 11  label: 1 pred: -0.255948 bl: -0.11325 POSS error_pred: 1.5774 error_bl: 1.23933 improvement: -0.338079
    min: -0.62  max: 0.56 avg: -0.04356
explanation: 


3: 1122  label: 1 pred: -0.315572 bl: -0.1862 IMP error_pred: 1.73073 error_bl: 1.40707 improvement: -0.323659
    min: -0.518  max: 0.341 avg: -0.125363
explanation: 


4: 26  label: 1 pred: -0.0697743 bl: 0.08365 POSS error_pred: 1.14442 error_bl: 0.839697 improvement: -0.30472
    min: -0.492  max: 0.587 avg: 0.0518875
explanation: 


5: 2516  label: -1 pred: 0.154534 bl: 0.0176 IMP error_pred: 1.33295 error_bl: 1.03551 improvement: -0.297439
    min: -0.329  max: 0.826 avg: 0.245552
explanation: 


6: 2204  label: 1 pred: -0.300605 bl: -0.18945 IMP error_pred: 1.69157 error_bl: 1.41479 improvement: -0.276783
    min: -0.5375  max: 0.193 avg: -0.197262
explanation: 


7: 556  label: -1 pred: 0.415844 bl: 0.318 IMP error_pred: 2.00461 error_bl: 1.73712 improvement: -0.267491
    min: -0.1895  max: 0.6395 avg: 0.27104
explanation: 


8: 1567  label: -1 pred: 0.471683 bl: 0.3803 IMP error_pred: 2.16585 error_bl: 1.90523 improvement: -0.260623
    min: -0.144  max: 0.7415 avg: 0.44164
explanation: 


9: 2662  label: 1 pred: -0.164808 bl: -0.048 IMP error_pred: 1.35678 error_bl: 1.0983 improvement: -0.258475
    min: -0.4065  max: 0.1995 avg: -0.111288
explanation: 


10: 1030  label: -0.5 pred: 0.578738 bl: 0.45525 IMP error_pred: 1.16368 error_bl: 0.912503 improvement: -0.251172
    min: 0.0285  max: 0.939 avg: 0.509898
explanation: 


11: 1574  label: -1 pred: 0.493703 bl: 0.4113 IMP error_pred: 2.23115 error_bl: 1.99177 improvement: -0.239383
    min: -0.1345  max: 0.7505 avg: 0.31241
explanation: 


12: 1992  label: 1 pred: 0.00121737 bl: 0.1207 IMP error_pred: 0.997567 error_bl: 0.773169 improvement: -0.224398
    min: -0.127  max: 0.468 avg: 0.153657
explanation: 


13: 2216  label: -1 pred: 0.519857 bl: 0.44665 IMP error_pred: 2.30996 error_bl: 2.0928 improvement: -0.217168
    min: -0.1085  max: 0.889 avg: 0.49062
explanation: 


14: 2594  label: 1 pred: -0.186542 bl: -0.0975 IMP error_pred: 1.40788 error_bl: 1.20451 improvement: -0.203377
    min: -0.3755  max: 0.2185 avg: -0.0728625
explanation: 


15: 1064  label: -1 pred: 0.203715 bl: 0.11625 IMP error_pred: 1.44893 error_bl: 1.24601 improvement: -0.202915
    min: -0.258  max: 0.799 avg: 0.193913
explanation: 


16: 1683  label: 1 pred: 0.0395012 bl: 0.1516 IMP error_pred: 0.922558 error_bl: 0.719783 improvement: -0.202775
    min: -0.169  max: 0.4735 avg: 0.122508
explanation: 


17: 638  label: 1 pred: 0.0626721 bl: 0.1716 POSS error_pred: 0.878583 error_bl: 0.686247 improvement: -0.192337
    min: -0.536  max: 0.7875 avg: 0.137097
explanation: 


18: 2832  label: 1 pred: -0.0953131 bl: -0.00755 IMP error_pred: 1.19971 error_bl: 1.01516 improvement: -0.184554
    min: -0.324  max: 0.3005 avg: -0.0053725
explanation: 


19: 968  label: 0.5 pred: -0.311803 bl: -0.19015 POSS error_pred: 0.659024 error_bl: 0.476307 improvement: -0.182716
    min: -0.7335  max: 0.5665 avg: -0.15398
explanation: 


20: 160  label: -0.5 pred: 0.528968 bl: 0.4365 POSS error_pred: 1.05878 error_bl: 0.877032 improvement: -0.181744
    min: -0.162  max: 0.95 avg: 0.493528
explanation: 


21: 856  label: 1 pred: -0.252331 bl: -0.183 IMP error_pred: 1.56833 error_bl: 1.39949 improvement: -0.168845
    min: -0.399  max: 0.1995 avg: -0.13392
explanation: 


22: 1822  label: 0.5 pred: -0.481888 bl: -0.3919 IMP error_pred: 0.964104 error_bl: 0.795486 improvement: -0.168618
    min: -0.8095  max: -0.0315 avg: -0.412
explanation: 


23: 1142  label: -1 pred: 0.350034 bl: 0.2863 IMP error_pred: 1.82259 error_bl: 1.65457 improvement: -0.168024
    min: -0.001  max: 0.4295 avg: 0.238795
explanation: 


24: 2274  label: 0.5 pred: -0.431418 bl: -0.33675 POSS error_pred: 0.867539 error_bl: 0.700151 improvement: -0.167389
    min: -0.691  max: 0.317 avg: -0.314127
explanation: 


25: 2170  label: -1 pred: 0.465855 bl: 0.4117 IMP error_pred: 2.14873 error_bl: 1.9929 improvement: -0.155834
    min: 0.044  max: 0.72 avg: 0.395733
explanation: 


26: 2452  label: -1 pred: 0.34198 bl: 0.2837 IMP error_pred: 1.80091 error_bl: 1.64789 improvement: -0.153025
    min: -0.0755  max: 0.6815 avg: 0.307645
explanation: 


27: 593  label: 0.5 pred: -0.105286 bl: 0.0376 POSS error_pred: 0.366371 error_bl: 0.213814 improvement: -0.152557
    min: -0.416  max: 0.291 avg: -0.0048875
explanation: 


28: 65  label: -1 pred: 0.392733 bl: 0.3388 IMP error_pred: 1.93971 error_bl: 1.79239 improvement: -0.147321
    min: -0.2035  max: 0.597 avg: 0.26529
explanation: 


29: 2673  label: 1 pred: -0.0990764 bl: -0.035 IMP error_pred: 1.20797 error_bl: 1.07122 improvement: -0.136744
    min: -0.1705  max: 0.2385 avg: 0.02102
explanation: 


30: 1786  label: 0.5 pred: -0.384754 bl: -0.30425 POSS error_pred: 0.78279 error_bl: 0.646818 improvement: -0.135972
    min: -0.7415  max: 0.142 avg: -0.26039
explanation: 


31: 2231  label: -1 pred: 0.370509 bl: 0.32005 IMP error_pred: 1.87829 error_bl: 1.74253 improvement: -0.135762
    min: -0.009  max: 0.6935 avg: 0.405828
explanation: 


32: 904  label: 0 pred: 0.649506 bl: 0.53665 POSS error_pred: 0.421858 error_bl: 0.287993 improvement: -0.133865
    min: 0.068  max: 0.943 avg: 0.483597
explanation: 


33: 2427  label: 0 pred: 0.733516 bl: 0.63645 POSS error_pred: 0.538046 error_bl: 0.405069 improvement: -0.132977
    min: 0.4015  max: 0.9475 avg: 0.70056
explanation: 


34: 509  label: 0.5 pred: -0.233106 bl: -0.13935 POSS error_pred: 0.537444 error_bl: 0.408768 improvement: -0.128676
    min: -0.9275  max: 0.016 avg: -0.195955
explanation: 


35: 1833  label: 0 pred: 0.624613 bl: 0.5124 POSS error_pred: 0.390141 error_bl: 0.262554 improvement: -0.127587
    min: 0.0215  max: 0.9175 avg: 0.447922
explanation: 


36: 367  label: -1 pred: 0.0378347 bl: -0.0253 IMP error_pred: 1.0771 error_bl: 0.95004 improvement: -0.127061
    min: -0.201  max: 0.1385 avg: -0.0683525
explanation: 


37: 303  label: 0.5 pred: -0.414422 bl: -0.3423 IMP error_pred: 0.836167 error_bl: 0.709469 improvement: -0.126698
    min: -0.5505  max: -0.095 avg: -0.365265
explanation: 


38: 1378  label: -0.5 pred: 0.367823 bl: 0.29195 IMP error_pred: 0.753116 error_bl: 0.627185 improvement: -0.125932
    min: 0.0125  max: 0.7525 avg: 0.413138
explanation: 


39: 1790  label: 0 pred: 0.691077 bl: 0.59335 POSS error_pred: 0.477587 error_bl: 0.352064 improvement: -0.125523
    min: 0.428  max: 0.9275 avg: 0.66782
explanation: 


40: 1799  label: -1 pred: 0.195698 bl: 0.1426 IMP error_pred: 1.42969 error_bl: 1.30553 improvement: -0.124159
    min: -0.0625  max: 0.516 avg: 0.2388
explanation: 


41: 1025  label: -1 pred: 0.294369 bl: 0.24555 IMP error_pred: 1.67539 error_bl: 1.55139 improvement: -0.123995
    min: -0.024  max: 0.587 avg: 0.273872
explanation: 


42: 2867  label: 1 pred: -0.0780331 bl: -0.02055 POSS error_pred: 1.16216 error_bl: 1.04152 improvement: -0.120633
    min: -0.901  max: 0.671 avg: 0.089075
explanation: 


43: 1759  label: -0.5 pred: 0.491806 bl: 0.4292 IMP error_pred: 0.98368 error_bl: 0.863413 improvement: -0.120267
    min: 0.0645  max: 0.5625 avg: 0.352875
explanation: 


44: 379  label: -1 pred: 0.461912 bl: 0.42065 IMP error_pred: 2.13719 error_bl: 2.01825 improvement: -0.11894
    min: -0.0025  max: 0.975 avg: 0.554218
explanation: 


45: 1807  label: -0.5 pred: 0.286695 bl: 0.20715 POSS error_pred: 0.618889 error_bl: 0.500061 improvement: -0.118828
    min: -0.197  max: 0.6895 avg: 0.253657
explanation: 


46: 439  label: 0.5 pred: -0.170547 bl: -0.0777 POSS error_pred: 0.449634 error_bl: 0.333737 improvement: -0.115896
    min: -0.361  max: 0.265 avg: -0.123012
explanation: 


47: 1441  label: -0.5 pred: 0.106912 bl: 0.00265 POSS error_pred: 0.368342 error_bl: 0.252657 improvement: -0.115685
    min: -0.326  max: 0.6555 avg: 0.108867
explanation: 


48: 2472  label: 1 pred: -0.0956896 bl: -0.0432 POSS error_pred: 1.20054 error_bl: 1.08827 improvement: -0.112269
    min: -0.341  max: 0.526 avg: 0.0153775
explanation: 


49: 2038  label: 0.5 pred: -0.186283 bl: -0.09915 POSS error_pred: 0.470984 error_bl: 0.358981 improvement: -0.112003
    min: -0.352  max: 0.3075 avg: -0.01845
explanation: 


best entries: 
0: 2143  label: -1 pred: -0.24543 bl: -0.03495 POSS error_pred: 0.569376 error_bl: 0.931321 improvement: 0.361945
1: 1427  label: -1 pred: -0.331078 bl: -0.1695 POSS error_pred: 0.447457 error_bl: 0.68973 improvement: 0.242273
2: 71  label: -0.5 pred: 0.810531 bl: 0.89945 IMP error_pred: 1.71749 error_bl: 1.95846 improvement: 0.24097
3: 560  label: -1 pred: -0.213634 bl: -0.08085 IMP error_pred: 0.618371 error_bl: 0.844837 improvement: 0.226465
4: 10  label: 1 pred: 0.368192 bl: 0.20995 POSS error_pred: 0.399182 error_bl: 0.624179 improvement: 0.224997
5: 470  label: -1 pred: -0.32421 bl: -0.17625 POSS error_pred: 0.456692 error_bl: 0.678564 improvement: 0.221872
6: 2464  label: -1 pred: -0.108801 bl: 0.000149998 IMP error_pred: 0.794235 error_bl: 1.0003 improvement: 0.206065
7: 1424  label: -0.5 pred: 0.78113 bl: 0.85875 IMP error_pred: 1.6413 error_bl: 1.8462 improvement: 0.204906
8: 2665  label: -1 pred: -0.342903 bl: -0.20425 POSS error_pred: 0.431776 error_bl: 0.633218 improvement: 0.201442
9: 1697  label: -1 pred: -0.212337 bl: -0.0941 POSS error_pred: 0.620413 error_bl: 0.820655 improvement: 0.200242
10: 2055  label: -1 pred: -0.208038 bl: -0.0925 IMP error_pred: 0.627204 error_bl: 0.823556 improvement: 0.196352
11: 1202  label: -1 pred: -0.209054 bl: -0.0985 IMP error_pred: 0.625596 error_bl: 0.812702 improvement: 0.187106
12: 2802  label: -1 pred: -0.140033 bl: -0.0386 IMP error_pred: 0.739543 error_bl: 0.92429 improvement: 0.184747
13: 2625  label: -1 pred: -0.405805 bl: -0.26775 POSS error_pred: 0.353067 error_bl: 0.53619 improvement: 0.183123
14: 47  label: -1 pred: -0.329635 bl: -0.2103 POSS error_pred: 0.44939 error_bl: 0.623626 improvement: 0.174236
15: 2125  label: -0.5 pred: -0.0639691 bl: 0.10295 POSS error_pred: 0.190123 error_bl: 0.363549 improvement: 0.173426
16: 1686  label: -1 pred: -0.332089 bl: -0.2155 POSS error_pred: 0.446104 error_bl: 0.61544 improvement: 0.169336
17: 1696  label: -1 pred: -0.215685 bl: -0.1159 POSS error_pred: 0.61515 error_bl: 0.781633 improvement: 0.166483
18: 848  label: 0 pred: -0.769464 bl: -0.8707 POSS error_pred: 0.592076 error_bl: 0.758119 improvement: 0.166043
19: 1910  label: -1 pred: -0.144093 bl: -0.05315 IMP error_pred: 0.732577 error_bl: 0.896525 improvement: 0.163948
20: 723  label: -1 pred: 0.168478 bl: 0.2365 IMP error_pred: 1.36534 error_bl: 1.52893 improvement: 0.163592
21: 1528  label: -1 pred: -0.0823255 bl: 0.00285 IMP error_pred: 0.842127 error_bl: 1.00571 improvement: 0.163582
22: 473  label: 1 pred: 0.452035 bl: 0.326 POSS error_pred: 0.300266 error_bl: 0.454276 improvement: 0.15401
23: 1388  label: -1 pred: -0.273815 bl: -0.1747 IMP error_pred: 0.527345 error_bl: 0.68112 improvement: 0.153775
24: 2713  label: -1 pred: -0.343063 bl: -0.23495 POSS error_pred: 0.431566 error_bl: 0.585302 improvement: 0.153736
25: 53  label: -1 pred: -0.381988 bl: -0.2692 IMP error_pred: 0.381939 error_bl: 0.534069 improvement: 0.152129
26: 2527  label: -1 pred: -0.430801 bl: -0.31095 POSS error_pred: 0.323987 error_bl: 0.47479 improvement: 0.150803
27: 54  label: 1 pred: 0.5795 bl: 0.4316 POSS error_pred: 0.17682 error_bl: 0.323079 improvement: 0.146259
28: 1393  label: -1 pred: 0.142189 bl: 0.2045 IMP error_pred: 1.3046 error_bl: 1.45082 improvement: 0.146224
29: 2025  label: -1 pred: -0.285845 bl: -0.19155 IMP error_pred: 0.510017 error_bl: 0.653591 improvement: 0.143574
30: 908  label: -1 pred: -0.418486 bl: -0.30595 POSS error_pred: 0.338158 error_bl: 0.481705 improvement: 0.143547
31: 2636  label: -0.5 pred: -0.191869 bl: -0.01215 POSS error_pred: 0.0949449 error_bl: 0.237998 improvement: 0.143053
32: 2691  label: -1 pred: -0.276297 bl: -0.18465 IMP error_pred: 0.523746 error_bl: 0.664796 improvement: 0.14105
33: 21  label: -1 pred: -0.264366 bl: -0.17465 POSS error_pred: 0.541157 error_bl: 0.681203 improvement: 0.140045
34: 965  label: -1 pred: -0.236766 bl: -0.1501 IMP error_pred: 0.582527 error_bl: 0.72233 improvement: 0.139803
35: 278  label: -0.5 pred: -0.00495011 bl: 0.1125 POSS error_pred: 0.245074 error_bl: 0.375156 improvement: 0.130082
36: 909  label: -1 pred: -0.23991 bl: -0.16 IMP error_pred: 0.577736 error_bl: 0.7056 improvement: 0.127864
37: 577  label: -1 pred: -0.282905 bl: -0.1992 IMP error_pred: 0.514225 error_bl: 0.641281 improvement: 0.127055
38: 782  label: 1 pred: 0.241883 bl: 0.16245 POSS error_pred: 0.574742 error_bl: 0.70149 improvement: 0.126748
39: 1907  label: -1 pred: -0.303851 bl: -0.21955 POSS error_pred: 0.484623 error_bl: 0.609102 improvement: 0.124479
40: 769  label: -0.5 pred: 0.666292 bl: 0.71705 IMP error_pred: 1.36024 error_bl: 1.48121 improvement: 0.120975
41: 549  label: 1 pred: 0.250123 bl: 0.1737 POSS error_pred: 0.562316 error_bl: 0.682772 improvement: 0.120456
42: 2335  label: -1 pred: -0.226323 bl: -0.1522 IMP error_pred: 0.598576 error_bl: 0.718765 improvement: 0.120189
43: 2496  label: 1 pred: 0.271287 bl: 0.19465 POSS error_pred: 0.531022 error_bl: 0.648589 improvement: 0.117566
44: 427  label: 1 pred: 0.468663 bl: 0.3679 POSS error_pred: 0.282319 error_bl: 0.39955 improvement: 0.117232
45: 1033  label: -1 pred: -0.362953 bl: -0.27715 IMP error_pred: 0.405829 error_bl: 0.522512 improvement: 0.116683
46: 2149  label: -1 pred: -0.448319 bl: -0.3531 IMP error_pred: 0.304352 error_bl: 0.41848 improvement: 0.114127
47: 2608  label: 1 pred: 0.20709 bl: 0.14005 IMP error_pred: 0.628706 error_bl: 0.739514 improvement: 0.110808
48: 471  label: -0.5 pred: 0.208611 bl: 0.282 POSS error_pred: 0.50213 error_bl: 0.611524 improvement: 0.109394
49: 740  label: 1 pred: 0.0500009 bl: -0.0055 IMP error_pred: 0.902498 error_bl: 1.01103 improvement: 0.108532

total is 0
score for UNKNOWN: nan baseline: nan diff:    nan
total is 1249
score for AUTO: 0.1643 baseline: 0.1584 diff: 0.0059
total is 1531
score for POSS: 0.4575 baseline: 0.4617 diff: -0.0042
total is 220
score for IMP: 1.0140 baseline: 1.0060 diff: 0.0080
writing 15000 official test outputs

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
scores: [ 0.439806 ]
0.4398 +/-    nan
524.92user 1.04system 1:45.05elapsed 500%CPU (0avgtext+0avgdata 0maxresident)k
0inputs+336outputs (0major+266108minor)pagefaults 0swaps

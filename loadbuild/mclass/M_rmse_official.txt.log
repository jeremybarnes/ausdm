loading data...applying decomposition
done.
training model 0
bag 4 of 50
bag 1 of 50
bag 2 of 50
bag 3 of 50
bag 5 of 50
bag 0 of 50
bag 6 of 50
bag 7 of 50
bag 8 of 50
bag 9 of 50
bag 10 of 50
bag 11 of 50
bag 12 of 50
bag 13 of 50
bag 14 of 50
bag 15 of 50
bag 16 of 50
bag 17 of 50
bag 18 of 50
bag 19 of 50
bag 20 of 50
bag 21 of 50
bag 22 of 50
bag 23 of 50
bag 24 of 50
bag 25 of 50
bag 26 of 50
bag 27 of 50
bag 28 of 50
bag 29 of 50
bag 30 of 50
bag 31 of 50
bag 32 of 50
bag 33 of 50
bag 34 of 50
bag 35 of 50
bag 36 of 50
bag 37 of 50
bag 38 of 50
bag 39 of 50
bag 40 of 50
bag 41 of 50
bag 42 of 50
bag 43 of 50
bag 44 of 50
bag 45 of 50
bag 46 of 50
bag 47 of 50
bag 48 of 50
bag 49 of 50
training model 1
bag 0 of 50
bag bag bag bag 2 of 150
3 of  of 50
50
5 of 50
bag 4 of 50
bag 7 of 50
bag 6 of 50
bag 8 of 50
bag 9 of 50
bag 10 of 50
bag 11 of 50
bag 12 of 50
bag 13 of 50
bag 14 of 50
bag 15 of 50
bag 16 of 50
bag 17 of 50
bag 18 of 50
bag 19 of 50
bag 20 of 50
bag 21 of 50
bag 22 of 50
bag 23 of 50
bag 24 of 50
bag 25 of 50
bag 26 of 50
bag 27 of 50
bag 28 of 50
bag 29 of 50
bag 30 of 50
bag 31 of 50
bag 32 of 50
bag 33 of 50
bag 34 of 50
bag 35 of 50
bag 36 of 50
bag 37 of 50
bag 38 of 50
bag 39 of 50
bag 40 of 50
bag 41 of 50
bag 42 of 50
bag 43 of 50
bag 44 of 50
bag 45 of 50
bag 46 of 50
bag 47 of 50
bag 48 of 50
bag 49 of 50
training model 2
bag 1 of 50
bag 0 of 50
bag 3 of 50
bag 4 of 50
bag 5 of 50
bag 6 of 50
bag 2 of 50
bag 7 of 50
bag 8 of 50
bag 9 of 50
bag 10 of 50
bag 11 of 50
bag 12 of 50
bag 13 of 50
bag 14 of 50
bag 15 of 50
bag 16 of 50
bag 17 of 50
bag 18 of 50
bag 19 of 50
bag 20 of 50
bag 21 of 50
bag 22 of 50
bag 23 of 50
bag 24 of 50
bag 25 of 50
bag 26 of 50
bag 27 of 50
bag 28 of 50
bag 29 of 50
bag 30 of 50
bag 31 of 50
bag 32 of 50
bag 33 of 50
bag 34 of 50
bag 35 of 50
bag 36 of 50
bag 37 of 50
bag 38 of 50
bag 39 of 50
bag 40 of 50
bag 41 of 50
bag 42 of 50
bag 43 of 50
bag 44 of 50
bag 45 of 50
bag 46 of 50
bag 47 of 50
bag 48 of 50
bag 49 of 50
training model 3
bag 1 of 50
bag 2 of 50
bag 0 of 50
bag 3 of 50
bag 4 of 50
bag 5 of 50
bag 6 of 50
bag 7 of 50
bag 8 of 50
bag 9 of 50
bag 10 of 50
bag 11 of 50
bag 12 of 50
bag 13 of 50
bag 14 of 50
bag 15 of 50
bag 16 of 50
bag 17 of 50
bag 18 of 50
bag 19 of 50
bag 20 of 50
bag 21 of 50
bag 22 of 50
bag 23 of 50
bag 24 of 50
bag 25 of 50
bag 26 of 50
bag 27 of 50
bag 28 of 50
bag 29 of 50
bag 30 of 50
bag 31 of 50
bag 32 of 50
bag 33 of 50
bag 34 of 50
bag 35 of 50
bag 36 of 50
bag 37 of 50
bag 38 of 50
bag 39 of 50
bag 40 of 50
bag 41 of 50
bag 42 of 50
bag 43 of 50
bag 44 of 50
bag 45 of 50
bag 46 of 50
bag 47 of 50
bag 48 of 50
bag 49 of 50
training model 4
bag 1 of 50
bag 0 of 50
bag 2 of 50
bag 5 of 50
bag 4 of 50
bag 3 of 50
bag 6 of 50
bag 7 of 50
bag 8 of 50
bag 9 of 50
bag 10 of 50
bag 11 of 50
bag 12 of 50
bag 13 of 50
bag 14 of 50
bag 15 of 50
bag 16 of 50
bag 17 of 50
bag 18 of 50
bag 19 of 50
bag 20 of 50
bag 21 of 50
bag 22 of 50
bag 23 of 50
bag 24 of 50
bag 25 of 50
bag 26 of 50
bag 27 of 50
bag 28 of 50
bag 29 of 50
bag 30 of 50
bag 31 of 50
bag 32 of 50
bag 33 of 50
bag 34 of 50
bag 35 of 50
bag 36 of 50
bag 37 of 50
bag 38 of 50
bag 39 of 50
bag 40 of 50
bag 41 of 50
bag 42 of 50
bag 43 of 50
bag 44 of 50
bag 45 of 50
bag 46 of 50
bag 47 of 50
bag 48 of 50
bag 49 of 50
training model 5
bag 1 of 50bag 0 of 50

bag 2 of 50
bag 3 of 50
bag 4 of 50
bag 5 of 50
bag 6 of 50
bag 7 of 50
bag 8 of 50
bag 10 of 50
bag 11 of 50
bag 12 of 50
bag 9 of 50
bag 13 of 50
bag 14bag  of 15 of 50
50
bag 16 of 50
bag 17 of 50
bag 18 of 50
bag 19 of 50
bag 20 of 50
bag 21 of 50
bag 22 of 50
bag 23 of 50
bag 24 of 50
bag 25 of 50
bag 26 of 50
bag 27 of 50
bag 28 of 50
bag 29 of 50
bag 30 of 50
bag 31 of 50
bag 32 of 50
bag 33 of 50
bag 34 of 50
bag 35 of 50
bag 36 of 50
bag 37 of 50
bag 38 of 50
bag 39 of 50
bag 40 of 50
bag 41 of 50
bag 42 of 50
bag 43 of 50
bag 44 of 50
bag 45 of 50
bag 46 of 50
bag 47 of 50
bag 48 of 50
bag 49 of 50
training model 6
bag 0 of 50
bag 1 of 50
bag 2 of 50
bag 3 of 50
bag 4 of 50
bag 5 of 50
bag 6bag  of 507
 of 50
bag 8 of 50
bag 9 of 50
bag 10 of 50
bag 11 of 50
bag 12 of 50
bag 13 of 50
bag 14 of 50
bag 15 of 50
bag 16 of 50
bag 17 of 50
bag 18 of 50
bag 19 of 50
bag 20 of 50
bag 21 of 50
bag 22 of 50
bag 23 of 50
bag 24 of 50
bag 25 of 50
bag 26 of 50
bag 27 of 50
bag 28 of 50
bag 29 of 50
bag 30 of 50
bag 31 of 50
bag 32 of 50
bag 33 of 50
bag 34 of 50
bag 35 of 50
bag 36 of 50
bag 37 of 50
bag 38 of 50
bag 39 of 50
bag 40 of 50
bag 41 of 50
bag 42 of 50
bag 43 of 50
bag 44 of 50
bag 45 of 50
bag 46 of 50
bag 47 of 50
bag 48 of 50
bag 49 of 50
training model 7
bag 0 of 50
bag bag 4 of 50
bag 1 of 50
2bag 3 of 50
 of 50
bag 5 of 50
bag 6 of 50
bag 7 of 50
bag 8 of 50
bag 9 of 50
bag 10 of 50
bag 11 of 50
bag 12 of 50
bag 13 of 50
bag 14 of 50
bag 15 of 50
bag 16 of 50
bag 17 of 50
bag 18 of 50
bag 19 of 50
bag 20 of 50
bag 21 of 50
bag 22 of 50
bag 23 of 50
bag 24 of 50
bag 25bag 26 of 50
 of 50
bag 27 of 50
bag 28 of 50
bag 29 of 50
bag 30 of 50
bag 31 of 50
bag 32 of 50
bag 33 of 50
bag 34 of 50
bag 35 of 50
bag 36 of 50
bag 37 of 50
bag 38 of 50
bag 39 of 50
bag 40 of 50
bag 41 of 50
bag 42 of 50
bag 43 of 50
bag 44 of 50
bag 45 of 50
bag 46 of 50
bag 47 of 50
bag 48 of 50
bag 49 of 50
params = { -0.0330204 -0.0173371 0.023121 0.032346 0.214155 0.0482895 0.0687467 0.255769 -0.1001 -0.0156832 -0.0404588 -0.00922523 0.032346 0.0115454 -0.0167221 -0.0252468 0.0568782 -0.159575 -0.0164556 -0.0632319 -0.0114893 0.0214597 -0.0634029 0.0330204 -0.0513319 0.131015 -0.0565589 0.032346 0.269638 -0.06656 0.396027 -0.236366 0.255769 0.0123077 -0.0764676 0.0647264 -0.208877 0.07519 -0.13432 -0.00460143 -0.00332242 -0.13312 0.0103901 -0.0178774 -0.0264021 0.0557228 -0.16073 -0.13312 }
chose model 84 M_rmse_85
chose model 36 M_rmse_37
chose model 17 M_rmse_18
chose model 172 M_rmse_173
chose model 180 M_rmse_181
chose model 196 M_rmse_197
chose model 213 M_rmse_214
chose model 5 M_rmse_6
chose model 211 M_rmse_212
chose model 121 M_rmse_122
processing 4000 predictions...

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
 done.
elapsed: [584.17s cpu, 527541.8009 mticks, 197.38s wall]
score: 0.4319  baseline: 0.4307  diff: 0.00114
category UNKNOWN: count 0 avg error 0 baseline avg error 0 avg improvement 0
category AUTO: count 1704 avg error 0.0253283 baseline avg error 0.0241654 avg improvement -0.00116288
category POSS: count 2029 avg error 0.19673 baseline avg error 0.201632 avg improvement 0.00490216
category IMP: count 267 avg error 1.13781 baseline avg error 1.09319 avg improvement -0.0446183
overall: count 4000 avg error 0.18653 baseline avg error 0.185543 avg improvement -0.00098704
worst entries: 
0: 343  label: -1 pred: 0.554753 bl: 0.3604 IMP error_pred: 2.41726 error_bl: 1.85069 improvement: -0.56657
    min: -0.1085  max: 0.9345 avg: 0.54374
explanation: 


1: 3452  label: -1 pred: -0.126857 bl: -0.4294 POSS error_pred: 0.762379 error_bl: 0.325584 improvement: -0.436795
    min: -0.969  max: 0.9725 avg: 0.002836
explanation: 


2: 2033  label: -1 pred: 0.468759 bl: 0.3129 IMP error_pred: 2.15725 error_bl: 1.72371 improvement: -0.433545
    min: -0.032  max: 0.817 avg: 0.389478
explanation: 


3: 3209  label: -1 pred: 0.646547 bl: 0.5197 IMP error_pred: 2.71112 error_bl: 2.30949 improvement: -0.401629
    min: -0.3515  max: 0.926 avg: 0.542084
explanation: 


4: 2045  label: -0.5 pred: 0.803656 bl: 0.6627 IMP error_pred: 1.69952 error_bl: 1.35187 improvement: -0.347649
    min: 0.321  max: 0.964 avg: 0.65505
explanation: 


5: 1422  label: -1 pred: 0.318391 bl: 0.1814 IMP error_pred: 1.73815 error_bl: 1.39571 improvement: -0.342448
    min: -0.287  max: 0.801 avg: 0.374506
explanation: 


6: 3644  label: -1 pred: 0.42282 bl: 0.30295 IMP error_pred: 2.02442 error_bl: 1.69768 improvement: -0.326739
    min: -0.2755  max: 0.6105 avg: 0.182396
explanation: 


7: 3660  label: -1 pred: 0.754788 bl: 0.66525 IMP error_pred: 3.07928 error_bl: 2.77306 improvement: -0.306222
    min: 0.5075  max: 0.975 avg: 0.690518
explanation: 


8: 2721  label: -1 pred: -0.400553 bl: -0.7675 POSS error_pred: 0.359337 error_bl: 0.0540562 improvement: -0.305281
    min: -1  max: 0.448 avg: -0.295502
explanation: 


9: 2929  label: -1 pred: 0.618197 bl: 0.52095 IMP error_pred: 2.61856 error_bl: 2.31329 improvement: -0.305272
    min: 0.309  max: 0.836 avg: 0.565474
explanation: 


10: 1032  label: -1 pred: -0.0127311 bl: -0.1818 POSS error_pred: 0.9747 error_bl: 0.669451 improvement: -0.305249
    min: -0.599  max: 0.4655 avg: -0.132496
explanation: 


11: 60  label: -1 pred: 0.261668 bl: 0.13445 IMP error_pred: 1.59181 error_bl: 1.28698 improvement: -0.304829
    min: -0.388  max: 0.536 avg: 0.185212
explanation: 


12: 3642  label: -1 pred: 0.166302 bl: 0.0311 IMP error_pred: 1.36026 error_bl: 1.06317 improvement: -0.297093
    min: -0.288  max: 0.5265 avg: 0.096736
explanation: 


13: 3806  label: -1 pred: 0.681497 bl: 0.59105 IMP error_pred: 2.82743 error_bl: 2.53144 improvement: -0.295991
    min: 0.097  max: 0.96 avg: 0.659574
explanation: 


14: 420  label: 0.5 pred: -0.612504 bl: -0.4724 IMP error_pred: 1.23766 error_bl: 0.945562 improvement: -0.292102
    min: -0.935  max: -0.148 avg: -0.472248
explanation: 


15: 2946  label: -1 pred: 0.296225 bl: 0.17975 IMP error_pred: 1.6802 error_bl: 1.39181 improvement: -0.28839
    min: -0.2075  max: 0.597 avg: 0.306006
explanation: 


16: 3954  label: -1 pred: -0.43484 bl: -0.80525 POSS error_pred: 0.319405 error_bl: 0.0379276 improvement: -0.281478
    min: -1  max: 0.5665 avg: -0.398432
explanation: 


17: 1108  label: -1 pred: 0.271404 bl: 0.15575 IMP error_pred: 1.61647 error_bl: 1.33576 improvement: -0.280709
    min: -0.165  max: 0.509 avg: 0.18167
explanation: 


18: 2094  label: -1 pred: -0.109889 bl: -0.2843 POSS error_pred: 0.792298 error_bl: 0.512227 improvement: -0.280071
    min: -0.52  max: 0.6525 avg: -0.107592
explanation: 


19: 3324  label: -0.5 pred: 0.746176 bl: 0.6306 IMP error_pred: 1.55295 error_bl: 1.27826 improvement: -0.274698
    min: 0.427  max: 0.9125 avg: 0.669878
explanation: 


20: 2774  label: -1 pred: 0.624314 bl: 0.53775 IMP error_pred: 2.6384 error_bl: 2.36468 improvement: -0.273721
    min: 0.1415  max: 0.837 avg: 0.507598
explanation: 


21: 2431  label: -0.5 pred: 0.690421 bl: 0.5709 IMP error_pred: 1.4171 error_bl: 1.14683 improvement: -0.270274
    min: 0.384  max: 0.7875 avg: 0.57257
explanation: 


22: 3135  label: -1 pred: 0.337192 bl: 0.23555 IMP error_pred: 1.78808 error_bl: 1.52658 improvement: -0.261498
    min: 0.0425  max: 0.5715 avg: 0.23935
explanation: 


23: 143  label: -1 pred: 0.615356 bl: 0.5324 IMP error_pred: 2.60938 error_bl: 2.34825 improvement: -0.261126
    min: -0.1205  max: 0.7805 avg: 0.604944
explanation: 


24: 1376  label: -1 pred: 0.167499 bl: 0.05225 IMP error_pred: 1.36305 error_bl: 1.10723 improvement: -0.255824
    min: -0.373  max: 0.468 avg: 0.01832
explanation: 


25: 48  label: -0.5 pred: 0.73946 bl: 0.63255 IMP error_pred: 1.53626 error_bl: 1.28267 improvement: -0.253592
    min: 0.2865  max: 0.9535 avg: 0.680022
explanation: 


26: 3933  label: -1 pred: 0.47169 bl: 0.3833 IMP error_pred: 2.16587 error_bl: 1.91352 improvement: -0.252353
    min: -0.006  max: 0.689 avg: 0.383414
explanation: 


27: 1950  label: -1 pred: 0.145899 bl: 0.03 IMP error_pred: 1.31308 error_bl: 1.0609 improvement: -0.252184
    min: -0.452  max: 0.4985 avg: 0.012502
explanation: 


28: 1073  label: 0 pred: 0.723718 bl: 0.5241 POSS error_pred: 0.523768 error_bl: 0.274681 improvement: -0.249088
    min: -0.0785  max: 0.945 avg: 0.603434
explanation: 


29: 3904  label: -0.5 pred: 0.590013 bl: 0.4692 IMP error_pred: 1.18813 error_bl: 0.939349 improvement: -0.248781
    min: 0.229  max: 0.906 avg: 0.492798
explanation: 


30: 2025  label: -0.5 pred: 0.624511 bl: 0.50835 IMP error_pred: 1.26452 error_bl: 1.01677 improvement: -0.247755
    min: 0.153  max: 0.9415 avg: 0.49504
explanation: 


31: 464  label: -0.5 pred: 0.48799 bl: 0.3536 POSS error_pred: 0.976125 error_bl: 0.728633 improvement: -0.247492
    min: -0.011  max: 0.7105 avg: 0.425804
explanation: 


32: 698  label: -1 pred: 0.0204671 bl: -0.109 IMP error_pred: 1.04135 error_bl: 0.793881 improvement: -0.247472
    min: -0.3245  max: 0.405 avg: 0.062996
explanation: 


33: 56  label: -1 pred: -0.0137051 bl: -0.14555 IMP error_pred: 0.972778 error_bl: 0.730085 improvement: -0.242693
    min: -0.4205  max: 0.2685 avg: -0.109578
explanation: 


34: 1924  label: -0.5 pred: 0.492782 bl: 0.36215 IMP error_pred: 0.985615 error_bl: 0.743303 improvement: -0.242313
    min: 0.1745  max: 0.7425 avg: 0.439736
explanation: 


35: 3525  label: -0.5 pred: 0.520465 bl: 0.39455 IMP error_pred: 1.04135 error_bl: 0.80022 improvement: -0.241129
    min: 0.2  max: 0.738 avg: 0.495108
explanation: 


36: 3384  label: -0.5 pred: 0.410854 bl: 0.2756 POSS error_pred: 0.829655 error_bl: 0.601555 improvement: -0.228099
    min: -0.169  max: 0.732 avg: 0.26981
explanation: 


37: 2007  label: -1 pred: -0.0185206 bl: -0.1352 IMP error_pred: 0.963302 error_bl: 0.747879 improvement: -0.215423
    min: -0.426  max: 0.655 avg: 0.003764
explanation: 


38: 3715  label: -1 pred: 0.202244 bl: 0.1094 IMP error_pred: 1.44539 error_bl: 1.23077 improvement: -0.214623
    min: -0.3155  max: 0.4965 avg: 0.112652
explanation: 


39: 3412  label: -0.5 pred: 0.372307 bl: 0.23975 POSS error_pred: 0.760919 error_bl: 0.54723 improvement: -0.213689
    min: -0.178  max: 0.6685 avg: 0.330802
explanation: 


40: 1510  label: -0.5 pred: 0.712822 bl: 0.62495 IMP error_pred: 1.47094 error_bl: 1.26551 improvement: -0.205424
    min: 0.3295  max: 0.8055 avg: 0.590942
explanation: 


41: 1596  label: -1 pred: 0.567146 bl: 0.50055 IMP error_pred: 2.45595 error_bl: 2.25165 improvement: -0.204295
    min: 0.126  max: 0.8255 avg: 0.514558
explanation: 


42: 269  label: 0 pred: 0.73674 bl: 0.58975 POSS error_pred: 0.542785 error_bl: 0.347805 improvement: -0.19498
    min: 0.36  max: 0.93 avg: 0.657162
explanation: 


43: 3541  label: -1 pred: -0.0357884 bl: -0.1424 IMP error_pred: 0.929704 error_bl: 0.735478 improvement: -0.194226
    min: -0.4995  max: 0.3285 avg: -0.112198
explanation: 


44: 1427  label: -0.5 pred: 0.392599 bl: 0.2789 POSS error_pred: 0.796732 error_bl: 0.606685 improvement: -0.190047
    min: -0.141  max: 0.808 avg: 0.386616
explanation: 


45: 1302  label: -1 pred: -0.304833 bl: -0.45605 POSS error_pred: 0.483257 error_bl: 0.295882 improvement: -0.187375
    min: -0.9335  max: 0.356 avg: -0.279102
explanation: 


46: 331  label: -1 pred: 0.0625242 bl: -0.02915 IMP error_pred: 1.12896 error_bl: 0.94255 improvement: -0.186408
    min: -0.372  max: 0.7005 avg: -0.03329
explanation: 


47: 119  label: -0.5 pred: 0.131399 bl: -0.03185 POSS error_pred: 0.398665 error_bl: 0.219164 improvement: -0.1795
    min: -0.2305  max: 0.79 avg: 0.117306
explanation: 


48: 1187  label: 0 pred: -0.710526 bl: -0.57185 POSS error_pred: 0.504848 error_bl: 0.327012 improvement: -0.177835
    min: -0.909  max: 0.0515 avg: -0.489562
explanation: 


49: 1652  label: -0.5 pred: 0.0946426 bl: -0.0804 POSS error_pred: 0.3536 error_bl: 0.176064 improvement: -0.177536
    min: -0.244  max: 0.3715 avg: -0.007332
explanation: 


best entries: 
0: 2211  label: 1 pred: 0.16079 bl: -0.0564 IMP error_pred: 0.704274 error_bl: 1.11598 improvement: 0.411707
1: 221  label: 1 pred: -0.0599502 bl: -0.2361 IMP error_pred: 1.12349 error_bl: 1.52794 improvement: 0.404449
2: 2813  label: 0.5 pred: -0.196125 bl: -0.43855 POSS error_pred: 0.484591 error_bl: 0.880876 improvement: 0.396285
3: 2515  label: 1 pred: 0.506547 bl: 0.26285 POSS error_pred: 0.243496 error_bl: 0.54339 improvement: 0.299894
4: 3590  label: 1 pred: 0.0444113 bl: -0.0918 IMP error_pred: 0.91315 error_bl: 1.19203 improvement: 0.278877
5: 1085  label: -1 pred: 0.629317 bl: 0.71065 IMP error_pred: 2.65467 error_bl: 2.92632 improvement: 0.271649
6: 2651  label: -0.5 pred: 0.645721 bl: 0.75845 POSS error_pred: 1.31268 error_bl: 1.5837 improvement: 0.27102
7: 2111  label: 1 pred: 0.312142 bl: 0.14185 POSS error_pred: 0.473149 error_bl: 0.736421 improvement: 0.263273
8: 1938  label: 1 pred: 0.0881855 bl: -0.0238 IMP error_pred: 0.831406 error_bl: 1.04817 improvement: 0.216761
9: 1570  label: 1 pred: -0.133432 bl: -0.21975 IMP error_pred: 1.28467 error_bl: 1.48779 improvement: 0.203121
10: 1126  label: 1 pred: 0.0344377 bl: -0.06515 IMP error_pred: 0.932311 error_bl: 1.13454 improvement: 0.202234
11: 633  label: -1 pred: 0.0519959 bl: 0.14355 IMP error_pred: 1.1067 error_bl: 1.30771 improvement: 0.201011
12: 2371  label: -1 pred: -0.612311 bl: -0.41295 POSS error_pred: 0.150302 error_bl: 0.344628 improvement: 0.194325
13: 2256  label: 0.5 pred: 0.0349287 bl: -0.13785 POSS error_pred: 0.216291 error_bl: 0.406853 improvement: 0.190561
14: 2481  label: 1 pred: 0.32225 bl: 0.1961 POSS error_pred: 0.459344 error_bl: 0.646255 improvement: 0.186911
15: 3879  label: 1 pred: 0.29994 bl: 0.18045 POSS error_pred: 0.490085 error_bl: 0.671662 improvement: 0.181578
16: 1454  label: 1 pred: 0.0816071 bl: -0.0107 IMP error_pred: 0.843446 error_bl: 1.02151 improvement: 0.178069
17: 758  label: 1 pred: 0.0490816 bl: -0.03915 IMP error_pred: 0.904246 error_bl: 1.07983 improvement: 0.175587
18: 3659  label: 1 pred: 0.309359 bl: 0.19245 POSS error_pred: 0.476985 error_bl: 0.652137 improvement: 0.175152
19: 1854  label: 1 pred: 0.47991 bl: 0.33255 POSS error_pred: 0.270493 error_bl: 0.445489 improvement: 0.174996
20: 3991  label: 1 pred: 0.214686 bl: 0.1125 IMP error_pred: 0.616719 error_bl: 0.787656 improvement: 0.170938
21: 663  label: 0.5 pred: 0.71018 bl: 0.9628 POSS error_pred: 0.0441757 error_bl: 0.214184 improvement: 0.170008
22: 3350  label: 1 pred: 0.582484 bl: 0.41425 POSS error_pred: 0.174319 error_bl: 0.343103 improvement: 0.168784
23: 518  label: 1 pred: 0.528881 bl: 0.37575 POSS error_pred: 0.221953 error_bl: 0.389688 improvement: 0.167735
24: 1837  label: 1 pred: 0.426636 bl: 0.2956 POSS error_pred: 0.328747 error_bl: 0.496179 improvement: 0.167433
25: 3702  label: 0.5 pred: -0.0262431 bl: -0.1593 POSS error_pred: 0.276932 error_bl: 0.434676 improvement: 0.157745
26: 2276  label: 0.5 pred: -0.0678599 bl: -0.1927 POSS error_pred: 0.322465 error_bl: 0.479833 improvement: 0.157369
27: 2349  label: 1 pred: 0.177462 bl: 0.08725 IMP error_pred: 0.676569 error_bl: 0.833113 improvement: 0.156544
28: 2899  label: 1 pred: 0.309522 bl: 0.20435 POSS error_pred: 0.47676 error_bl: 0.633059 improvement: 0.156299
29: 3223  label: 1 pred: 0.332774 bl: 0.22445 POSS error_pred: 0.44519 error_bl: 0.601478 improvement: 0.156287
30: 773  label: 1 pred: 0.174775 bl: 0.08515 IMP error_pred: 0.680996 error_bl: 0.836951 improvement: 0.155954
31: 3668  label: 1 pred: 0.427498 bl: 0.30585 POSS error_pred: 0.327759 error_bl: 0.481844 improvement: 0.154085
32: 203  label: -1 pred: -0.290508 bl: -0.1893 POSS error_pred: 0.503379 error_bl: 0.657234 improvement: 0.153855
33: 625  label: 1 pred: 0.240935 bl: 0.14725 POSS error_pred: 0.576179 error_bl: 0.727183 improvement: 0.151003
34: 3809  label: -1 pred: -0.490603 bl: -0.3595 POSS error_pred: 0.259485 error_bl: 0.41024 improvement: 0.150755
35: 819  label: 1 pred: 0.138897 bl: 0.0563 POSS error_pred: 0.741498 error_bl: 0.89057 improvement: 0.149072
36: 781  label: 1 pred: 0.551511 bl: 0.40845 POSS error_pred: 0.201142 error_bl: 0.349931 improvement: 0.148789
37: 3516  label: -0.5 pred: 0.254188 bl: 0.34635 POSS error_pred: 0.568799 error_bl: 0.716308 improvement: 0.147509
38: 2203  label: -1 pred: -0.233246 bl: -0.14245 POSS error_pred: 0.587912 error_bl: 0.735392 improvement: 0.14748
39: 72  label: 0.5 pred: 0.100348 bl: -0.0535 POSS error_pred: 0.159722 error_bl: 0.306362 improvement: 0.146641
40: 1687  label: 1 pred: 0.439336 bl: 0.32155 POSS error_pred: 0.314344 error_bl: 0.460294 improvement: 0.14595
41: 665  label: 1 pred: 0.539602 bl: 0.40315 POSS error_pred: 0.211966 error_bl: 0.35623 improvement: 0.144264
42: 2867  label: -0.5 pred: -0.0452982 bl: 0.09055 POSS error_pred: 0.206754 error_bl: 0.348749 improvement: 0.141996
43: 1174  label: 1 pred: 0.60956 bl: 0.45805 POSS error_pred: 0.152444 error_bl: 0.29371 improvement: 0.141266
44: 3667  label: 1 pred: 0.273 bl: 0.18175 POSS error_pred: 0.528529 error_bl: 0.669533 improvement: 0.141004
45: 530  label: 1 pred: -0.116155 bl: -0.17745 IMP error_pred: 1.2458 error_bl: 1.38639 improvement: 0.140586
46: 1467  label: 1 pred: 0.21862 bl: 0.1361 POSS error_pred: 0.610555 error_bl: 0.746323 improvement: 0.135768
47: 2507  label: -1 pred: -0.302726 bl: -0.21255 POSS error_pred: 0.486191 error_bl: 0.620078 improvement: 0.133886
48: 2024  label: 1 pred: 0.703344 bl: 0.529 POSS error_pred: 0.0880046 error_bl: 0.221841 improvement: 0.133836
49: 3065  label: 1 pred: 0.535639 bl: 0.40935 POSS error_pred: 0.215631 error_bl: 0.348867 improvement: 0.133236

total is 0
score for UNKNOWN: nan baseline: nan diff:    nan
total is 1704
score for AUTO: 0.1591 baseline: 0.1555 diff: 0.0037
total is 2029
score for POSS: 0.4435 baseline: 0.4490 diff: -0.0055
total is 267
score for IMP: 1.0667 baseline: 1.0456 diff: 0.0211
writing 20000 official test outputs

0%   10   20   30   40   50   60   70   80   90   100%
|----|----|----|----|----|----|----|----|----|----|
***************************************************
scores: [ 0.431891 ]
0.4319 +/-    nan
771.72user 1.46system 4:45.37elapsed 270%CPU (0avgtext+0avgdata 0maxresident)k
0inputs+448outputs (0major+325789minor)pagefaults 0swaps
